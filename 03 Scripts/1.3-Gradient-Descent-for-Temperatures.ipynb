{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb06020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode\n",
    "from plotly.offline import plot, iplot\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b992c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a path to where your data is stored.\n",
    "path = r'/Users/yourname/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the European weather data.\n",
    "climate = pd.read_csv(os.path.join(path, 'DATASET.csv'))\n",
    "climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce to just the mean temperatures\n",
    "df = climate[['DATE', 'MONTH','BASEL_temp_mean',\n",
    " 'BELGRADE_temp_mean',\n",
    " 'BUDAPEST_temp_mean',\n",
    " 'DEBILT_temp_mean',\n",
    " 'DUSSELDORF_temp_mean',\n",
    " 'GDANSK_temp_mean',\n",
    " 'HEATHROW_temp_mean',\n",
    " 'KASSEL_temp_mean',\n",
    " 'LJUBLJANA_temp_mean',\n",
    " 'MAASTRICHT_temp_mean',\n",
    " 'MADRID_temp_mean',\n",
    " 'MUNCHENB_temp_mean',\n",
    " 'OSLO_temp_mean',\n",
    " 'ROMA_temp_mean',\n",
    " 'SONNBLICK_temp_mean',\n",
    " 'STOCKHOLM_temp_mean',\n",
    " 'TOURS_temp_mean',\n",
    " 'VALENTIA_temp_mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28670a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a856771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You'll need to reduce the dataset to only one year of data. Analyze and pick which year you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00dc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the DATE and MONTH data as those numbers are not scaled with the rest.\n",
    "notemp = df.drop(['DATE','MONTH'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at a whisker plot of the data to see variations in temperatures\n",
    "notemp.boxplot(figsize=(15,15))\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739173ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce your dataset to a single year\n",
    "dfyear = df[df['DATE'].astype(str).str.contains('1960')] #<-----INSERT YEAR HERE\n",
    "dfyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cd7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfyear.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0554de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick which weather station you want to use. Below is a 3D visualization of the temperatures for that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the DATE and MONTH data as those numbers are not scaled with the rest.\n",
    "notempyear = dfyear.drop(['DATE','MONTH'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b15968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot ALL weather data for all stations for a year \n",
    "\n",
    "#X = weather station\n",
    "#Y = day of the year\n",
    "#Z = temperature\n",
    "\n",
    "#you can click/hold in the graph below to rotate!\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(z=notempyear.values)])\n",
    "fig.update_layout(title='Temperatures over time', autosize=False,\n",
    "                  width=600, height=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to make an index for the year. Create a set of data from 1 to 365 (or to 366 if it's a leap year!)\n",
    "#We'll scale this by 100 as the index is made. This will help teh gradient descent converge 366 = 3.66\n",
    "\n",
    "i = np.arange(0.01,3.66,0.01) #<---needs to be one GREATER than the total number of days\n",
    "index = pd.DataFrame(data = i, columns = ['index'])\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7897a22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = dfyear.shape[0]\n",
    "n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f19f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will translate your chosen weather data into the X and y datasets needed for the optimization function.\n",
    "\n",
    "X=index.to_numpy().reshape(n_rows,1)\n",
    "#Represent x_0 as a vector of 1s for vector computation\n",
    "ones = np.ones((n_rows,1))\n",
    "X = np.concatenate((ones, X), axis=1)\n",
    "y=dfyear['STATION_temp_mean'].to_numpy().reshape(n_rows,1) #<----INSERT WEATHER STATION HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd319406",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at one year of temperature data over time\n",
    "plt.scatter(x=index['index'], y=dfyear['STATION_temp_mean']) #<----INSERT WEATHER STATION HERE\n",
    "plt.xlabel('X'); plt.ylabel('y');\n",
    "plt.title('Input dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ab6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the min temperature? (Note gradient descent is not actually finding this number)\n",
    "dfyear['STATION_temp_mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb51050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the max temperature? (Note gradient descent is not actually finding this number)\n",
    "dfyear['STATION_temp_mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e7ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This computes the loss function for the gradiant descent. DO NOT CHANGE!\n",
    "\n",
    "def compute_cost(X, y, theta=np.array([[0],[0]])):\n",
    "    \"\"\"Given covariate matrix X, the prediction results y and coefficients theta\n",
    "    compute the loss\"\"\"\n",
    "    \n",
    "    m = len(y)\n",
    "    J=0 # initialize loss to zero\n",
    "    \n",
    "    # reshape theta\n",
    "    theta=theta.reshape(2,1)\n",
    "    \n",
    "    # calculate the hypothesis - y_hat\n",
    "    h_x = np.dot(X,theta)\n",
    "    #print(h_x)\n",
    "    \n",
    "    # subtract y from y_hat, square and sum\n",
    "    error_term = sum((h_x - y)**2)\n",
    "    \n",
    "    # divide by twice the number of samples - standard practice.\n",
    "    loss = error_term/(2*m)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aec9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_cost(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38627745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the gradiant descent function. DO NOT CHANGE!\n",
    "\n",
    "def gradient_descent(X, y, theta=np.array([[0],[0]]),\n",
    "                    alpha=0.01, num_iterations=1500):\n",
    "    \"\"\"\n",
    "    Solve for theta using Gradient Descent optimiztion technique. \n",
    "    Alpha is the learning rate\n",
    "    \"\"\"\n",
    "    m = len(y)\n",
    "    J_history = []\n",
    "    theta0_history = []\n",
    "    theta1_history = []\n",
    "    theta = theta.reshape(2,1)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        error = (np.dot(X, theta) - y)\n",
    "        \n",
    "        term0 = (alpha/m) * sum(error* X[:,0].reshape(m,1))\n",
    "        term1 = (alpha/m) * sum(error* X[:,1].reshape(m,1))\n",
    "        \n",
    "        # update theta\n",
    "        term_vector = np.array([[term0],[term1]])\n",
    "        #print(term_vector)\n",
    "        theta = theta - term_vector.reshape(2,1)\n",
    "        \n",
    "        # store history values\n",
    "        theta0_history.append(theta[0].tolist()[0])\n",
    "        theta1_history.append(theta[1].tolist()[0])\n",
    "        J_history.append(compute_cost(X,y,theta).tolist()[0])\n",
    "        \n",
    "    return (theta, J_history, theta0_history, theta1_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615cda81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#This runs your data through a gradiant descent for the starting conditions in 'theta_init.'\n",
    "#You will need to adjust these numbers\n",
    "\n",
    "num_iterations=10 #<---Decide how many iterations you need. Start small and work up. Over 10,000 iterations will take a few seconds.\n",
    "theta_init=np.array([[-10],[-5]]) #<---this is where you put the guess for [theta0], [theta1]. Start with 1 and 1.\n",
    "alpha=0.1 #<---Decide what your step size is. Try values between 0.1 and 0.00001. You will need to adjust your iterations.\n",
    "#If your solution is not converging, try a smaller step size.\n",
    "theta, J_history, theta0_history, theta1_history = gradient_descent(X,y, theta_init,\n",
    "                                                                   alpha, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f53115",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ffa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will plot your loss, theta0, and theta1.If the result looks like a straight line, it's not converging on an answer!\n",
    "#Your loss (red) should be trending toward 0.\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# plot thetas over time\n",
    "color='tab:blue'\n",
    "ax1.plot(theta0_history, label='$\\\\theta_{0}$', linestyle='--', color=color)\n",
    "ax1.plot(theta1_history, label='$\\\\theta_{1}$', linestyle='-', color=color)\n",
    "# ax1.legend()\n",
    "ax1.set_xlabel('Iterations'); ax1.set_ylabel('$\\\\theta$', color=color);\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# plot loss function over time\n",
    "color='tab:red'\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(J_history, label='Loss function', color=color)\n",
    "ax2.set_title('Values of $\\\\theta$ and $J(\\\\theta)$ over iterations')\n",
    "ax2.set_ylabel('Loss: $J(\\\\theta)$', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# ax2.legend();\n",
    "fig.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ed155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# theta range\n",
    "theta0_vals = np.linspace(-10,10,100) #Look in the chart above for the limits of where theta0 and theta1 appear.\n",
    "theta1_vals = np.linspace(-10,10,100) #Put those values as the first two \"linspace\" numbers in these lines\n",
    "                                      #Select with large margins, maybe +/- 10\n",
    "J_vals = np.zeros((len(theta0_vals), len(theta1_vals)))\n",
    "\n",
    "# compute cost for each combination of theta\n",
    "c1=0; c2=0\n",
    "for i in theta0_vals:\n",
    "    for j in theta1_vals:\n",
    "        t = np.array([i, j])\n",
    "        J_vals[c1][c2] = compute_cost(X, y, t.transpose()).tolist()[0]\n",
    "        c2=c2+1\n",
    "    c1=c1+1\n",
    "    c2=0 # reinitialize to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097228b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This figure shows the loss function.\n",
    "\n",
    "#X = Theta0\n",
    "#Y - Theta1\n",
    "#Z = Loss\n",
    "#Find where it is closest to 0 in X and Y!\n",
    "\n",
    "#you can click/hold in the graph below to rotate!\n",
    "\n",
    "fig = go.Figure(data=[go.Surface(x=theta1_vals, y=theta0_vals, z=J_vals)])\n",
    "fig.update_layout(title='Loss function for different thetas', autosize=True,\n",
    "                  width=600, height=600, xaxis_title='theta0', \n",
    "                 yaxis_title='theta1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the same figure as above, with the line the loss function takes toward the minimum.\n",
    "\n",
    "#X = Theta0\n",
    "#Y - Theta1\n",
    "#Z = Loss\n",
    "#black line = path of loss function over the iterations.\n",
    "#Find where it is closest to 0 in X and Y!\n",
    "\n",
    "#you can click/hold in the graph below to rotate!\n",
    "\n",
    "line_marker = dict(color='#101010', width=2)\n",
    "fig = go.Figure()\n",
    "fig.add_surface(x=theta1_vals, y=theta0_vals, z=J_vals)\n",
    "fig.add_scatter3d(x=theta1_history, y=theta0_history, z=J_history, line=line_marker, name='')\n",
    "#The below line adds a graph of just the loss over iterations in a 2D plane\n",
    "plt.plot(theta0_history, theta1_history, 'r+');\n",
    "fig.update_layout(title='Loss function for different thetas', autosize=True,\n",
    "                  width=600, height=600, xaxis_title='theta0', \n",
    "                 yaxis_title='theta1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerun the optimization above, but this time start closer to the objective!\n",
    "#Find where the black line ends near the lowest X/Y/Z coordinate and make that your guess below.\n",
    "\n",
    "num_iterations=10 #<---start with the same iterations as above\n",
    "theta_init=np.array([[1],[1]]) #<---make a guess as to a more accurate [x],[y] coordinates near the minimum in the graph above.\n",
    "alpha= 0.1 #<---start with the same step size as above\n",
    "theta1, J_history1, theta0_history1, theta1_history1 = gradient_descent(X,y, theta_init,\n",
    "                                                                   alpha, num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c593cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at the new loss path on the function. It should start much closer to the goal\n",
    "\n",
    "line_marker = dict(color='#101010', width=2)\n",
    "fig = go.Figure()\n",
    "fig.add_surface(x=theta1_vals, y=theta0_vals, z=J_vals)\n",
    "fig.add_scatter3d(x=theta1_history1, y=theta0_history1, z=J_history1, line=line_marker, name='')\n",
    "#The below line adds a graph of just the loss over iterations in a 2D plane\n",
    "plt.plot(theta0_history1, theta1_history1, 'r+');\n",
    "fig.update_layout(title='Loss function for different thetas', autosize=True,\n",
    "                  width=600, height=600, xaxis_title='theta0', \n",
    "                 yaxis_title='theta1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This plot shows the convergence similar to above, but only in the X/Y plane (there's no height)\n",
    "\n",
    "plt.contour(theta0_vals, theta1_vals, J_vals, levels = np.logspace(0,10,1000))\n",
    "plt.xlabel('$\\\\theta_{0}$'); plt.ylabel(\"$\\\\theta_{1}$\")\n",
    "plt.title(\"Contour plot of loss function for different values of $\\\\theta$s\");\n",
    "plt.plot(theta0_history1, theta1_history1, 'r+');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How well does gradient descent converge? How much do you need to adjust between different weather stations and years?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
